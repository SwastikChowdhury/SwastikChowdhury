## ğŸš€ About Me
ğŸ‘‹ Hi, Iâ€™m **Swastik Chowdhury** â€” a Data Engineer & Machine Learning Engineer with 5+ years of experience leading large-scale data and AI initiatives! <br>
ğŸ“ Graduate Student @ Carnegie Mellon University<br>
ğŸš€ Actively seeking full-time roles starting August 2025<br<br>
ğŸ“ **Location:** Pittsburgh, PA, USA <br>
ğŸ’¼ **Open to:** Data Engineering, Machine Learning Engineering, Software Engineering roles<br>
ğŸ“ **Blog:** [https://medium.com/@swastiksc1996](https://medium.com/@swastiksc1996)<br>
ğŸ”— **LinkedIn:** [linkedin.com/in/swastik-chowdhury](https://linkedin.com/in/swastik-chowdhury)<br>

---

## ğŸ› ï¸ Technical Skills
ğŸ’» **Languages:** Python, Scala, Java, SQL<br>
ğŸ—„ï¸ **Databases:** Oracle SQL, MongoDB, Cassandra, Redis, Neo4j<br>
ğŸ›¢ï¸ **Big Data:** Spark, PySpark, Kafka, Hadoop<br>
ğŸ“Š **Analytics:** Hypothesis Testing, A/B Testing, Survival Analysis, ML, DL, GenAI, NLP<br>
ğŸ¢ **Data Warehousing:** Redshift, BigQuery, Iceberg, Hive, Trino<br>
âš™ï¸ **DevOps/MLOps:** Docker, Airflow, dbt, RabbitMQ, Jenkins, Ansible, ArgoCD, Kubernetes, Istio, Prometheus, Grafana, Git, Bash, Postman, Zeno, MLflow<br>
â˜ï¸ **Cloud:** AWS, GCP<br>
ğŸ“ˆ **BI/Visualization:** Tableau, QuickSight<br>

---

## ğŸ† Key Achievements
**Cost Optimization:** Led migration from Amazon Redshift to EMR using Apache Spark, saving $1M+ annually<br>
**Real-Time Data Ingestion:** Designed CDC pipelines with Debezium, Kafka, and Iceberg for scalable, real-time analytics<br>
**Spark Optimization:** Reduced Spark job costs by 15%+ through advanced resource allocation and workload analysis<br>
**AI Product Development:** Built a production-ready tool for document indexing using LlamaIndex and LLMs, streamlining support and knowledge sharing<br>
**Teaching:** Graduate Teaching Assistant for Machine Learning in Production/AI Engineering at CMU, mentoring teams on deploying ML systems in production<br>

---
